# -*- coding: utf-8 -*-
"""Proyek Akhir: Membuat Model Sistem Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17BxJogEheeyM9k59WJLaS6Vi8qksxmp1

https://www.kaggle.com/datasets/thedevastator/discovering-hidden-trends-in-global-video-games

Discovering Hidden Trends in Global Video Games

## Mengunduh Data
"""

! pip install -q kaggle

from google.colab import files

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d thedevastator/discovering-hidden-trends-in-global-video-games

!mkdir discovering-hidden-trends-in-global-video-games
!unzip discovering-hidden-trends-in-global-video-games.zip -d discovering-hidden-trends-in-global-video-games
!ls discovering-hidden-trends-in-global-video-games

"""## Mepersiapkan Data"""

#Importing the Libraries
import numpy as np
import pandas as pd
import datetime
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics

import warnings
import sys
if not sys.warnoptions:
    warnings.simplefilter("ignore")
np.random.seed(42)
from functools import reduce
pd.set_option('display.max_columns', None)

dataset = pd.read_csv('/content/discovering-hidden-trends-in-global-video-games/Video Games Sales.csv')

dataset

dataset.info()

"""## Membersihkan Data

### Memilih FItur
"""

dataset.rename(columns = {'index':'User_ID', 'Game Title':'Game_Title'}, inplace = True)
selected_df = dataset[['User_ID', 'Game_Title',	'Platform',	'Year',	'Genre',	'Publisher', 'Review']]

clean_df = selected_df.dropna()

clean_df.info()

clean_df.head()

"""### Format Ulang Fitur"""

print('Jumlah User ID: ', len(clean_df.User_ID.unique()))
print('Jumlah Nama Game: ', len(clean_df.Game_Title.unique()))
print('Jumlah Genre: ', len(clean_df.Genre.unique()))

clean_df['Review'] = round(clean_df['Review'])
clean_df

clean_df.info()

"""### Membuat Game ID Produk"""

LE = LabelEncoder()

clean_df['Game_ID'] = LE.fit_transform(clean_df['Game_Title'])

clean_df

for col in clean_df:
    print(f"\033[1m{col} \n{20 * '-'}\033[0m")
    print(clean_df[col].value_counts(), '\n')

"""### Menghapus Data Duplikasi"""

clean_df = clean_df.drop_duplicates('Game_ID')
clean_df = clean_df.reset_index(drop=True)
clean_df

"""## Exploratory Data Analysis

### Variabel Kategorik
"""

clean_df['Year'] = clean_df['Year'].astype(int)

import matplotlib as mpl

categorical_columns = ['Platform', 'Year', 'Genre', 'Publisher']

plt.figure(figsize = (20,40))
COLOR = 'blue'
mpl.rcParams['text.color'] = COLOR
mpl.rcParams['axes.labelcolor'] = COLOR
mpl.rcParams['xtick.color'] = COLOR
mpl.rcParams['ytick.color'] = COLOR
for i in range(0, len(categorical_columns)):
    plt.subplot(4, 1, i+1)
    ax = sns.countplot(x=clean_df[categorical_columns[i]], palette='winter', orient='h')
    ax.tick_params(axis='both', which='major', pad=10)
    plt.xticks(rotation=90,fontsize=10)
    plt.yticks(fontsize=10)
    plt.ylabel(ylabel='Count',fontsize=15)
    plt.xlabel(xlabel=categorical_columns[i],fontsize=15)

clean_df['Year'] = clean_df['Year'].astype(str)

clean_df.describe(include=object)

"""### Variabel Numerik"""

clean_df.describe()

"""## Model Development dengan Content Based Filtering"""

game_id = clean_df['Game_ID'].tolist()
 
genre = clean_df['Genre'].tolist()
 
title = clean_df['Game_Title'].tolist()
 
print(len(game_id))
print(len(genre))
print(len(title))

product_new = pd.DataFrame({
    'game_id': game_id,
    'genre': genre,
    'title': title
})
product_new

first_df = product_new
first_df.sample(5)

"""### TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
tf.fit(first_df['genre']) 
tf.get_feature_names()

tfidf_matrix = tf.fit_transform(first_df['genre']) 
 
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=first_df['title']
).sample(10, axis=1).sample(10, axis=0)

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity
 
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=first_df['title'], columns=first_df['title'])
print('Shape:', cosine_sim_df.shape)
 
cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi"""

def resto_recommendations(nama_resto, similarity_data=cosine_sim_df, items=first_df[['title', 'genre']], k=5):
    index = similarity_data.loc[:,nama_resto].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(nama_resto, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

first_df[first_df.title.eq('Grand Theft Auto: San Andreas')]

resto_recommendations('Grand Theft Auto: San Andreas')

"""## Model Development dengan Collaborative Filtering"""

user_id = clean_df['User_ID'].tolist()
 
game_id = clean_df['Game_ID'].tolist()

title = clean_df['Game_Title'].tolist()

platform = clean_df['Platform'].tolist()

year = clean_df['Year'].tolist()

genre = clean_df['Genre'].tolist()

publisher = clean_df['Publisher'].tolist()

rating = clean_df['Review'].tolist()

print(len(user_id))
print(len(game_id))
print(len(rating))

rating_new = pd.DataFrame({
    'user_id': user_id,
    'game_id' : game_id,
    'title' : title,
    'platform' : platform,
    'year' : year,
    'genre' : genre,
    'publisher' : publisher,
    'rating': rating
})
rating_new

second_df = rating_new
second_df.sample(5)

"""### Mempersiapkan Data"""

user_ids = second_df['user_id'].unique().tolist()
print('list user_id: ', user_ids)
 
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)
 
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

game_ids = second_df['game_id'].unique().tolist()
 
game_to_game_encoded = {x: i for i, x in enumerate(game_ids)}
 
game_encoded_to_game = {i: x for i, x in enumerate(game_ids)}

second_df['user'] = second_df['user_id'].map(user_to_user_encoded)

second_df['game'] = second_df['game_id'].map(game_to_game_encoded)

num_users = len(user_to_user_encoded)
print(num_users)
 
num_game = len(game_to_game_encoded)
print(num_game)
 
min_rating = min(second_df['rating'])
 
max_rating = max(second_df['rating'])
 
print('Number of User: {}, Number of Game: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_game, min_rating, max_rating
))

"""### Membagi Data untuk Training dan Validasi"""

second_df = second_df.sample(frac=1, random_state=42)
second_df

x = second_df[['user','game']].values
 
y = second_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
train_indices = int(0.8 * second_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""### Proses Training"""

from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

class RecommenderNet(tf.keras.Model):
 
  def __init__(self, num_users, num_game, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_game = num_game
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.game_embedding = layers.Embedding(
        num_game,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.game_bias = layers.Embedding(num_game, 1)
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0]) 
    game_vector = self.game_embedding(inputs[:, 1])
    game_bias = self.game_bias(inputs[:, 1])
 
    dot_user_game = tf.tensordot(user_vector, game_vector, 2) 
 
    x = dot_user_game + user_bias + game_bias
    
    return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_game, 50)
 
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""### Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Mendapatkan Rekomendasi Game"""

game_df = product_new
rating_df = rating_new
 
user_id = rating_df['user_id'].sample(1).iloc[0]
game_played_by_user = rating_df[rating_df['user_id'] == user_id]
 
game_not_played = game_df[~game_df['game_id'].isin(game_played_by_user['game_id'].values)]['game_id'] 
game_not_played = list(
    set(game_not_played)
    .intersection(set(game_to_game_encoded.keys()))
)
 
game_not_played = [[game_to_game_encoded.get(x)] for x in game_not_played]
user_encoder = user_to_user_encoded.get(user_id)
user_game_array = np.hstack(
    ([[user_encoder]] * len(game_not_played), game_not_played)
)

ratings = model.predict(user_game_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_game_ids = [
    game_encoded_to_game.get(game_not_played[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('========' * 8)
print('Game with high ratings from user')
print('--------' * 8)
 
top_game_user = (
    game_played_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .game_id.values
)
 
game_df_rows = game_df[game_df['game_id'].isin(top_game_user)]
for row in game_df_rows.itertuples():
    print(row.title, ':', row.genre)
 
print('--------' * 8)
print('Top 10 Game Recommendation')
print('--------' * 8)
 
recommended_game = game_df[game_df['game_id'].isin(recommended_game_ids)]
for row in recommended_game.itertuples():
    print(row.title, ':', row.genre)

second_df.loc[second_df['user_id'] == 676]